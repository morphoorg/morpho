#!/usr/bin/env python
#
# Morpho
#  -----------------------------------------------------
#  Authors: J. A. Formaggio <josephf@mit.edu>
#           J. Johnston <jpj13@mit.edu>
#           T. E. Weiss <tweiss@mit.edu>
#           M. Guigue <mathieu.guigue@pnnl.gov>
#           J. N. Kofron <jared.kofron@gmail.com>
#

"""
Executeable to process data, run stan, and make plots
Classes:
  - morpho: Class that controls flow of the morpho code
Functions:
  - get_logger_stderr: Return logger that prints messages greater than
    a given level to std_err
  - stan_cache: Cache the Stan model, then run stan
  - parse_args: Parse morpho command line arguments
  - update_from_arguments: Update the dictionary with morpho arguments
  - change_and_format: Try to convert a string into boolean or float
  - merge: Merge two dictionaries
  - plot_result: Plot a variable in a stanfit object
  - write_result: Write results from a stanfit object to file
  - preprocessing: Import and run preprocessing modules
  - postprocessing: Import and run postprocessing modules
  - plotting: Import and run plotting modules
  - save_object: Pickle an object
  - __main__: Run morpho
"""

from __future__ import absolute_import

import os,sys
try:
    reload  # Python 2.7
except NameError:
    try:
        from importlib import reload  # Python 3.4+
    except ImportError:
        from imp import reload  # Python 3.0 - 3.3
    reload(sys)
# sys.setdefaultencoding("utf-8")

import time
import re
import random
import ast

try:
    import pystan
    import pickle
    import colorlog
    from yaml import load as yload
except ImportError:
    pass

from argparse import ArgumentParser
from inspect import getargspec

from hashlib import md5
import importlib

import logging


def get_logger_stderr(name, formatter, stderr_lb=logging.ERROR,
                      level=logging.DEBUG, propagate=False):
    """Return a logger than prints high logging level messages to stderr
    Args:
        name: Name of the logger. Loggers are conceptually arranged
            in a namespace hierarchy using periods as separators.
            For example, a logger named morpho is the parent of a
            logger named morpho.plot, and by default the child logger
            will display messages with the same settings as the parent
        formatter: A Formatter object used to format all output
        stderr_lb: Messages with level equal to or greaterthan stderr_lb
             will be printed to stderr instead of stdout
        level: Initial level for the logger
        propagate: Whether messages to this logger should be passed to
             the handlers of its ancestor
    Returns:
        logging.Logger: Logger object with the given settings
    """

    logger = logging.getLogger(name)
    logger.setLevel(level)
    logger.propagate = propagate

    class LessThanFilter(logging.Filter):
        """Filter to get messages less than a given level
        """
        def __init__(self, exclusive_maximum, name=""):
            super(LessThanFilter, self).__init__(name)
            self.max_level = exclusive_maximum

        def filter(self, record):
            #non-zero return means we log this message
            return 1 if record.levelno < self.max_level else 0

    logger.handlers = []
    handler_stdout = logging.StreamHandler(sys.stdout)
    handler_stdout.setFormatter(formatter)
    handler_stdout.setLevel(logging.DEBUG)
    handler_stdout.addFilter(LessThanFilter(stderr_lb))
    logger.addHandler(handler_stdout)
    handler_stderr = logging.StreamHandler(sys.stderr)
    handler_stderr.setFormatter(formatter)
    handler_stderr.setLevel(stderr_lb)
    logger.addHandler(handler_stderr)
    return logger

# Create morpho and pystan loggers
# Will be reinstantiated after parsing command line args if __main__ is run
base_format = '%(asctime)s{}[%(levelname)-8s] %(name)s(%(lineno)d) -> {}%(message)s'
morpho_formatter = colorlog.ColoredFormatter(
        base_format.format('%(log_color)s', '%(purple)s'),
        datefmt = '%Y-%m-%dT%H:%M:%SZ'[:-1],
        reset=True,
        )
propagate_morpho_loggers=False
logger = get_logger_stderr('morpho', morpho_formatter,
                           stderr_lb=logging.WARNING,
                           propagate=propagate_morpho_loggers)
logger_stan = get_logger_stderr('pystan', morpho_formatter,
                                stderr_lb=logging.WARNING,
                                propagate=propagate_morpho_loggers)

class morpho(object):
    """Object containing and controlling data to run stan
    Functions:
      - read_param: Read a parameter from a dictionary
      - gen_arg_dict: Generate dictionary with stan arguments
      - init_Stan_functions: Determine initialization for stan chains
      - get_do_Stan: Accessor for self.do_stan
      - get_do_prep: Accessor for self.do_preprocessing
      - get_do_pp: Accessor for self.do_postprocessing
      - get_do_plots: Accessor for self.do_plots
      - get_wait: Accessor for self.wait
        
    Attributes:
      - do_preprocessing: Whether Morpho should do preprocessing before
        running Stan
      - do_stan: Whether Morpho should run Stan
      - do_postprocessing: Whether Morpho should do postprocessing after
        running Stan
      - do_plots: Whether Morpho should make plots after running Stan
      - wait: Whether Morpho should wait for input at the end before
        exiting
      - job_id: String to append to output file names, in order to
        enable batching
      - model_code: Location of Stan model file
      - function_files_location: Location of stan functions files
      - model_name: Name of Stan model
      - cashe_dir: Name of directory that the Stan model code is written
        to or read from
      - datafiles: Names of input data files
      - iter: Number of iterations for each stan chain
      - warmup: Number of iterations that should be considered warmup
      - chains: Number of chains to run
      - n_jobs: Number of CPUs used to sample in parallel. If -1 all CPUs
        are used. If 1, no parallel computing code is used at all.
      - seed: Random number seed
      - thin: Integer specifying thinning for stan iterations
      - init_per_chain: Dictionary of variable initializations for one
        chain
      - init: List of dictionaries with variable initializations for all
        chains
      - control: A dictionary of parameters (including 'adapt_delta')
        controlling various aspects of the sampler's behavior. For more
        information and default values, see
        http://pystan.readthedocs.io/en/latest/api.html.
      - plot_vars: Dictionary with plot settings
      - out_format: Format used to store stan output
      - out_fname: Filename used to store stan output
      - out_option: Options used while storing stan output
      - out_tree: Name of tree used to store stan output in a root file
      - out_branches: Names of branches used to store stan output in a
        root file
      - out_inc_warmup: Whether warmup iterations should be stored with
        stan output
      - out_cfg: Output config (not implemented)
      - out_fit: Filename for output pickled fit
      - out_cache_fn: Filename of saved cache file
      - prep_dict: Dictionary with preprocessing settings
      - pp_dict: Dictionary with postprocessing settings
      - plot_dict: Dictionary with plot settings
    """
    def read_param(self, yaml_data, node, default):
        """Read a parameter from a dictionary using the given node
        Args:
            yaml_data: Input dictionary
            node: String indicating a path through the dictionary. The
                series of keys should be separated by periods. For
                example, 'key1.key2.key3' would try to access
                yaml_data['key1']['key2']['key3'].
            default: Value to return if the path given by node does not
                exist. Set to 'required' in order to throw an exception
                if the path does not exist.
        Returns:
            Object: Returns the accessed element
        """
        data = yaml_data
        xpath = node.split('.')
        try:
            for path in xpath:
                data = data[path]
        except Exception as exc:
            if default == 'required':
                err = """FATAL: Configuration parameter {0} required but not\
                provided in config file!
                """.format(node)
                logger.debug(err)
                raise exc
            else:
                data = default
        return data

    def gen_arg_dict(self):
        """Generate a dictionary from the morpho object for use by Stan
        Args:
            None
        Returns:
            dict: Searches the morpho namespace for keys that appear in
            the arguments for stan_cache and pystan.stan, and returns
            all of those keys and elements as a dictionary
        """
        d = self.__dict__
        sca = getargspec(stan_cache)
        sa = getargspec(pystan.stan)
        return {k: d[k] for k in (sa.args + sca.args) if k in d}

    def init_Stan_function(self):
        """Determine initialization for stan chains
        Args:
            None
        Returns:
            list of dict: List with length equal to the number of chains
                set by self.chains. Each element of the list is a dict
                containing initialization values for that chain.
        """
        if isinstance(self.init_per_chain,list): 
            # init_per_chain is a list of dictionaries
            if self.chains >1 and len(self.init_per_chain)==1:
                dict_list = [self.init_per_chain[0]] * self.chains
                return dict_list
            elif len(self.init_per_chain)==self.chains :
                return self.init_per_chain
            else:
                logger.error('Number of chains is not equal to the size of the list of dictionaries')
                return self.init_per_chain
        elif isinstance(self.init_per_chain,dict): 
            # init_per_chain is a dictionary
            if self.chains >1:
                return [self.init_per_chain] * self.chains
            else:
                return [self.init_per_chain]
        else:
            return self.init_per_chain

    def get_do_Stan(self):
        """Return self.do_stan"""
        if self.do_stan==True:
            return True
        else:
            return False
    def get_do_prep(self):
        """Return self.do_preprocessing"""
        if self.do_preprocessing:
            return True
        else:
            return False
    def get_do_pp(self):
        """Return self.do_postprocessing"""
        if self.do_postprocessing:
            return True
        else:
            return False
    def get_do_plots(self):
        """Return self.do_plots"""
        if self.do_plots:
            return True
        else:
            return False
    def get_wait(self):
        """Return self.wait"""
        if self.wait:
            return True
        else:
            return False

    def __init__(self, yd):
        """Initialize all attribute using the given dictionary
        Args:
            yd: Dictionary containing all Morpho settings
        """
        try:
            # Morpho steps
            self.do_preprocessing = self.read_param(yd, 'morpho.do_preprocessing', False)
            self.do_stan = self.read_param(yd, 'morpho.do_stan', True)
            self.do_postprocessing = self.read_param(yd, 'morpho.do_postprocessing', False)
            self.do_plots = self.read_param(yd, 'morpho.do_plots', False)
            self.wait = self.read_param(yd, 'morpho.wait_at_the_end', False)

            # batch identification
            if isinstance(args.job_id,(int,float,str)):
                self.job_id = str(args.job_id)
            else:
                self.job_id = None

            # STAN model stuff
            self.model_code = self.read_param(yd, 'stan.model.file', 'required')
            self.function_files_location = self.read_param(yd, 'stan.model.function_files_location', None)
            self.model_name = self.read_param(yd, 'stan.model.model_name', None)
            self.cashe_dir = self.read_param(yd, 'stan.model.cache', './cache')

            # STAN data
            self.datafiles = self.read_param(yd, 'stan.data', None)

            # STAN run conditions
            self.algorithm = self.read_param(yd, 'stan.run.algorithm', 'NUTS')
            self.iter = int(self.read_param(yd, 'stan.run.iter', 2000))
            self.warmup = int(self.read_param(yd, 'stan.run.warmup', self.iter/2))
            self.chains = int(self.read_param(yd, 'stan.run.chain', 4))
            # number of jobs to run (-1: all CPUS, 1: 1 CPU, good for debugging)
            self.n_jobs = int(self.read_param(yd, 'stan.run.n_jobs',-1))
            # Adding a seed based on extra arguments, current time
            if isinstance(args.seed,(int,float,str)):
                self.seed=int(args.seed)
            elif args.noautoseed:
                self.seed = int(random.random()*1000000000) # seed based on random.random and the current system time
                logger.debug("Autoseed activated")
            else:
                self.seed = int(self.read_param(yd, 'stan.run.seed', None))
            logger.debug("seed = {}".format(self.seed))


            self.thin = self.read_param(yd, 'stan.run.thin', 1)
            self.init_per_chain = self.read_param(yd, 'stan.run.init', '')
            self.init = self.init_Stan_function()
            if isinstance(self.read_param(yd, 'stan.run.control', None),dict):
                self.control = self.read_param(yd, 'stan.run.control', None)
            else:
                if self.read_param(yd, 'stan.run.control', None) is not None:
                    logger.debug("stan.run.control should be a dict: {}",str(self.read_param(yd, 'stan.run.control', None)))

            # plot and print information
            self.plot_vars = self.read_param(yd, 'stan.plot', None)

            # output information
            self.out_format = self.read_param(yd, 'stan.output.format', 'root')
            self.out_fname = self.read_param(yd, 'stan.output.name','stan_out.root')
            self.out_option = self.read_param(yd, 'stan.output.option','RECREATE')

            self.out_tree = self.read_param(yd, 'stan.output.tree', None)
            self.out_branches = self.read_param(yd, 'stan.output.branches', None)
            self.out_inc_warmup = self.read_param(yd,'stan.output.inc_warmup',False)

            self.out_cfg = self.read_param(yd, 'stan.output.config', None)

            # Outputted pickled fit filename
            self.out_fit = self.read_param(yd, 'stan.output.fit', None)

            # Outputted text file containing name of cache file
            self.out_cache_fn = self.read_param(yd, 'stan.output.save_cache_name', None)

            # Pre-processing configuration
            if self.do_preprocessing:
                self.prep_dict = self.read_param(yd, 'preprocessing.which_pp', None)

            # Post-processing configuration
            if self.do_postprocessing:
                self.pp_dict = self.read_param(yd, 'postprocessing.which_pp', None)

            # Plot configuration
            if self.do_plots:
                self.plot_dict = self.read_param(yd, 'plot.which_plot', None)

        except Exception as err:
            raise err

def stan_cache(model_code, function_files_location, model_name=None, cashe_dir='.',**kwargs):
    '''Cache a Stan model then run Stan
    Args:
        model_code: Path to the stan model
        function_files_location: Path to the function files
        model_name: Name of the stan model
        cashe_dir: Path to directory to store or access the stan model
        kwargs: Arguments that should be passed to the StanModel object
    Returns:
        (dict, stanfit): Returns the arguments for sampling (kwargs)
        and the result of the sampling
    '''
    theModel = open(model_code,'r+').read()
    match =  re.findall(r'\s*include\s*=\s*(?P<function_name>\w+)\s*;*',theModel)
    if function_files_location is not None:
        logger.debug('Looking for the functions to import in {}'.format(function_files_location))
        from os import listdir
        from os.path import isfile, join
        onlyfiles = [f for f in listdir(function_files_location) if isfile(join(function_files_location, f))]
    else:
        logger.debug('No functions file location given')
        onlyfiles = []
    for matches in match:
        found = False
        for filename in onlyfiles:
            if filename.endswith('.functions'):
                key = filename[:-10]
            elif  filename.endswith('.stan'):
                key = filename[:-5]
            else:
                continue
            if (key==matches):
                StanFunctions = open(function_files_location+'/'+filename,'r+').read()
                theModel = re.sub(r'\s*include\s*=\s*'+matches+'\s*;*\n',StanFunctions, theModel, flags=re.IGNORECASE)
                found = True
                logger.debug('Function file <{}> to import was found'.format(matches))
                continue
        if found == False:
            logger.critical('A function <{}> to import is missing'.format(matches))
    logger.debug('Import function files: complete')

    code_hash = md5(theModel.encode('ascii')).hexdigest()
    if model_name is None:
        cache_fn = '{}/cached-model-{}.pkl'.format(cashe_dir, code_hash)
    else:
        cache_fn = '{}/cached-{}-{}.pkl'.format(cashe_dir, model_name, code_hash)

    cdir = os.path.dirname(cache_fn)
    if not os.path.exists(cdir):
        os.makedirs(cdir)
        logger.info("Creating 'cache' folder: {}".format(cdir))

    if (args.force_restart):
        logger.debug("Forced to create Stan cache!")
        sm = pystan.StanModel(model_code=theModel)
        if not args.no_cache:
            logger.debug("Saving Stan cache in {}".format(cache_fn))
            with open(cache_fn, 'wb') as f:
                pickle.dump(sm, f)
    else:
        try:
            logger.debug("Trying to load cached StanModel")
            sm = pickle.load(open(cache_fn, 'rb'))
        except:
            logger.debug("None exists -> creating Stan cache")
            sm = pystan.StanModel(model_code=theModel)
            if not args.no_cache:
                logger.debug("Saving Stan cache in {}".format(cache_fn))
                with open(cache_fn, 'wb') as f:
                    pickle.dump(sm, f)
        else:
            logger.debug("Using cached StanModel: {}".format(cache_fn))

    if sa.out_cache_fn is not None:
        logger.debug("Saving cache file to {}".format(sa.out_cache_fn))
        cache_name_file = open(sa.out_cache_fn,'w+')
        cache_name_file.write(cache_fn)

    logger.info("Starting the sampling")
    text = "Parameters: \n"
    for key, value in kwargs.items():
        if key != "data" and key != "init" :
            text = text + "{}\t{}\n".format(key,value)
        elif key == "data":
            text = text + "data\t[...]\n"
        elif key == "init":
            text = text + "init\t[...]\n"
    logger.info(text)
    # returns the arguments for sampling and the result of the sampling
    return kwargs, sm.sampling(**kwargs)

def parse_args():
    '''Parse the command line arguments provided to morpho
    Args:
        None
    Returns:
        namespace: Namespace containing the arguments
    '''
    p = ArgumentParser(description='''
        An analysis tool for Project 8 data.
    ''')
    p.add_argument('-c','--config',
                   metavar='<configuration file>',
                   help='Full path to the configuration file used by morpho',
                   required=True)
    p.add_argument('--job_id',
                   metavar='<job_id>',
                   help='Job id number or string for batching',
                   required=False)
    p.add_argument('-s','--seed',
                   metavar='<seed>',
                   help='Add random seed number to file',
                   required=False)
    p.add_argument('-nas','--noautoseed',
                   action='store_false',
                   default=True,
                   help='Generate the seed based on the current time in ms',
                   required=False)
    p.add_argument('param',nargs='*',
                   default=False,
                   help='Manualy change of a parameter and its value')
    p.add_argument('-f','--force-restart',
                   action='store_true',
                   default=False,
                   help='Force the recompilation',
                   required=False)
    p.add_argument('-nc','--no-cache',
                    action='store_true',
                    default=False,
                    help='Do not save the Stan cache file',
                    required=False)
    p.add_argument('-v', '--verbosity', default='DEBUG',
                   metavar='<verbosity>',
                   help="Specify verbosity of the logger, with options DEBUG, INFO, WARNING, ERROR, or CRITICAL (Default: DEBUG)",
                   choices=['DEBUG','INFO','WARNING','ERROR','CRITICAL'],
                   required=False)
    p.add_argument('-sev', '--stderr-verbosity', default='WARNING',
                   metavar='<stderr_verbosity>',
                   help="Messages with level greater than or equal to the given verbosity will be redirected to stderr (Default: WARNING)",
                   choices=['DEBUG','INFO','WARNING','ERROR','CRITICAL'],
                   required=False)
    return p.parse_args()

def update_from_arguments(the_dict,args):
    '''Update a dictionary
    Args:
        the_dict: Dictionary to update
        args: Dictionary to merge into the_dict
    Returns:
        dict: Dictionary with args merged into the_dict
    '''
    logger.debug('Update dict parameters')
    new_dict = the_dict
    for a_arg in args:
        result = a_arg.split('=')
        xpath = result[0].split('.')
        to_update_dict = {xpath[-1]:ast.literal_eval(result[1])}
        for path in reversed(xpath[:-1]):
            to_update_dict = {path:to_update_dict}
        new_dict = merge(new_dict,to_update_dict)
    return new_dict

def change_and_format(b):
    """Try to convert a string into a boolean or float
    Args:
        b: String containing a boolean or float
    Returns:
        bool, float, or str: If b == 'True' or 'False', then the
        corresponding boolean is returns. Otherwise, if b can be
        converted into a float, the float is returned. Otherwise
        b is returned.
    """
    if b == 'True':
        return True
    elif b == 'False':
        return False
    else:
        try:
            a = float(b)
            return a
        except:
            return b

def merge(a, b, path=None):
    '''Merge two dictionaries
    Args:
        a: Base dictionary
        b: Dictionary to merge into a
        path: Location to merge b at
    Returns:
        dict: Merged dictionary
    '''
    if path is None: path = []
    for key in b:
        if key in a:
            if isinstance(a[key], dict) and isinstance(b[key], dict):
                merge(a[key], b[key], path + [str(key)])
            elif a[key] == b[key]:
                pass # same leaf value
            else:
                a[key] = change_and_format( b[key])
        else:
            a[key] = change_and_format( b[key])
    return a

def plot_result(conf, stanres):
    """Plot a variable from a stanfit object
    Args:
        conf.plotvars: List of dictionaries containing the names of
            variables to plot. Each dictionary should contain a
            'variable' key that contains the variable name.
        stanres: StanFit object resulting from Stan sampling
    Returns:
        None: Uses the plot method of stanres to plot the variable
    """
    fit = stanres.extract()
    if conf.plot_vars is not None:
        for var in conf.plot_vars:
            parname = var['variable']
            if parname not in fit:
                warning = """WARNING: data {0} not found in fit!  Skipping...
                """.format(parname)
                logger.debug(warning)
            else:
                stanres.plot(parname)

def write_result(conf, stanres, input_param):
    """Write results from a stanfit object to file
    Args:
        conf: Morpho object used to do the Stan sampling
        stanres: StanFit object resulting from Stan sampling
        input_param: Parameter to write
    Returns:
        StanFit: Write the result to file then returns the StanFit
        object
    """
    logger.info("Writing results!")
    try:
        from morpho.loader import pystanLoad as pyL
    except ImportError:
        pass
    ofilename = conf.out_fname
    rdir = os.path.dirname(ofilename)
    if not os.path.exists(rdir):
        os.makedirs(rdir)
        logger.info("Creating 'results' folder: {}".format(rdir))
    if (not conf.job_id is None):
        ofilename = ofilename+'_'+conf.job_id
    if conf.out_format == 'hdf5':
        #ofilename = ofilename+'.h5'
        pyL.write_result_hdf5(sa, ofilename, stanres, input_param)

    if conf.out_format == 'root':
        ofilename = ofilename+'.root'
        pyL.stan_write_root(conf, ofilename, stanres, input_param)
    return stanres

def preprocessing(sa):
    """import and run all preprocessing modules
    Args:
        sa: Morpho object containing preprocessing configuration
    Returns:
        None: Runs all preprocessing modules defined in the Morpho
            object initialization
    """
    # Generic function for creating the PreProcessing class
    if sa.prep_dict is None:
        logger.critical("preprocessing dict is None")
        return 0
    for minidict in sa.prep_dict:
        try:
            modulename = 'morpho.preprocessing.'+minidict['module_name']
            i = importlib.import_module("{}".format(modulename))
        except Exception as err:
            try:
                import imp
                i = imp.load_source(minidict['module_name'], minidict['module_name']+'.py')
                # i = importlib.import_module("{}".format(minidict['module_name']))
            except Exception as err:
                logger.critical(err)
                return 0
            else:
                logger.info("Doing preprocessing {} using {}".format(minidict['method_name'],minidict['module_name']+'.py'))
        else:
            logger.info("Doing preprocessing {} using {}".format(minidict['method_name'],modulename))

        try:
            getattr(i,minidict['method_name'])(minidict)
        except Exception as err:
            logger.critical(err)
    return 1

def postprocessing(sa):
    """Import and run all postprocessing modules
    Args:
        sa: Morpho object containing postprocessing configuration
    Returns:
        None: Runs all postprocessing modules defined in the Morpho
            object initialization
    """
    # Generic function for creating the PostProcessing class
    if sa.pp_dict is None:
        logger.critical("postprocessing dict is None")
        return 0
    for minidict in sa.pp_dict:
        try:
            modulename = 'morpho.postprocessing.'+minidict['module_name']
            i = importlib.import_module("{}".format(modulename))
        except Exception as err:
            try:
                import imp
                i = imp.load_source(minidict['module_name'], minidict['module_name']+'.py')
                # i = importlib.import_module("{}".format(minidict['module_name']))
            except Exception as err:
                logger.critical(err)
                return 0
            else:
                logger.info("Doing postprocessing {} using {}".format(minidict['method_name'],minidict['module_name']+'.py'))
        else:
            logger.info("Doing postprocessing {} using {}".format(minidict['method_name'],modulename))

        try:
            getattr(i,minidict['method_name'])(minidict)
        except Exception as err:
            logger.critical(err)
    return 1

def plotting(sa):
    """Import and run all plotting modules
    Args:
        sa: Morpho object containing plotting configuration
    Returns:
        None: Runs all plotting modules defined in the Morpho
            object initialization
    """

    # Generic function for plotting
    list_canvas = []
    if sa.plot_dict is None:
        logger.critical("plot dict is None")
        return 0
    for minidict in sa.plot_dict:
        try:
            modulename = 'morpho.plot.'+minidict['module_name']
            i = importlib.import_module("{}".format(modulename))
        except Exception as err:
            try:
                import imp
                i = imp.load_source(minidict['module_name'], minidict['module_name']+'.py')
                # i = importlib.import_module("{}".format(minidict['module_name']))
            except Exception as err:
                logger.critical(err)
                return 0
            else:
                logger.info("Doing plot {} using {}".format(minidict['method_name'],minidict['module_name']+'.py'))
        else:
            logger.info("Doing plot {} using {}".format(minidict['method_name'],modulename))

        try:
            list_canvas.append(getattr(i,minidict['method_name'])(minidict))
        except Exception as err:
            logger.critical(err)
            return 0
    return list_canvas

def save_object(obj, filename):
    """Save an object to file in the pickle format
    Args:
        obj: Object to save
        filname: Output file name
    Returns:
        None: The object is saved to file
    """
    logger.info("Saving into pickle file: {}".format(filename))
    with open(filename, 'wb') as output:
        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)

if __name__ == '__main__':

    print('\n\
                                                   ..ZDD8.\n\
                                                .?D?I.DD$D\n\
                                               D$???8$IDD,$\n\
                                             8N7ZI?III?DDD\n\
                                           8DIII?I$???ID.,\n\
                                         .$D78?OI?I7?INDDD\n\
                                  ..    DN$7$7IO8??+I?DDD\n\
                                  8    $D$$77I$7I?I??IDD\n\
 ~ND+II??I7NOO8.          D,     O    ZDZ$$7$8OZI77$O?DD)\n\
O.NN.I7?III?787INNZD..      M.   1   ZO$$ZZ$$777III?ID.8\n\
DDDN?IIIIIIIIII7$$$$DDZ8    .N  7   8OZZZZZ$$$7III??IDD=\n\
 D,DD?I????II87I77$$$ZZDD$~   N M  ZOOZZO$$$$$7I7II?OD.O\n\
  .:,NII$I?II7I8$$7$$ZZZZON8N  ND:ZDZZ8Z88OOO8777I?INDD.\n\
   DDDD7?IIII??77$$ZO$ZZZOOZND$DDZNZOZZZZ$$$$$$7III7N?\n\
     O.$8I?III?II$$$$$ZZZO8OND$DO8ZZZ$$Z$$$7$77ZIIIN\n\
      .DDNII?7IIZ7$$$8$7ZZZZ$ZZ8D$Z$Z7ZZZ$77$777I$D\n\
       D.,D??I?II7I7$$$$$$$ZZ$$DDD$$$$$7O$7777IIIZDD\n\
         DDDOI?7I7777D$$O$ZO7$8ZD8N$$$O7$$7IOIII??DD.\n\
          MDDD+?IIIZ$7$77$7$$$8$7MDD77I7ZIIIII??7IDD\n\
           =D.DDII?III777Z777787I.D?I7O???IZ???I?8D.$\n\
              ...DID?7I7I777I?I7ID  8I?III?7?II8?DDD.\n\
                DDD77I$III?8?II??D  DI??????Z?I?DN.N\n\
                 NNDI????8???I?$??D N7?I?????OI?NDD.\n\
                  DDD??II?I??I?II?D +DI?I?I?II7ND+N\n\
                  `?D8?I+?I?I7II??NN D8?7?I???DNDN\n\
                   .D,DD??Z?III???DN  NN7?IIDDM.D\n\
                    `DDDDIO???IIINN    N.DDDNDNN\n\
                      .D.DDDN7IND~M     DNDDD.\n\
                        DDD.DDN.DD        ..\n\
                          .7..ID$\n\
                            ...')

    print('\n\
                              _        \n\
           _ __  ___ _ _ _ __| |_  ___ \n\
          |    \/ _ \  _|  _ \   \/ _ \ \n\
          |_|_|_\___/_| | .__/_||_\___/ \n\
                        |_|            ')

    args = parse_args()
    logger = get_logger_stderr('morpho', morpho_formatter,
                               level=getattr(logging,args.verbosity),
                               stderr_lb=getattr(logging,args.stderr_verbosity),
                               propagate=propagate_morpho_loggers)
    logger_stan = get_logger_stderr('pystan', morpho_formatter,
                               level=getattr(logging,args.verbosity),
                               stderr_lb=getattr(logging,args.stderr_verbosity),
                               propagate=propagate_morpho_loggers)
    with open(args.config, 'r') as cfile:
        try:
            cdata = yload(cfile)
            if args.param:
                cdata = update_from_arguments(cdata,args.param)
            sa = morpho(cdata)
        except Exception as err:
            logger.critical("Caught exception")
            raise
            sys.exit(2)

        if (sa.get_do_prep()):
            preprocessing(sa)

        if (sa.get_do_Stan()):
            try:
                logger.info("Doing MC with Stan")
                if sa.datafiles is not None:
                    try:
                        from morpho.loader import pystanLoad as pyL
                    except ImportError:
                        pass
                    sa.data = pyL.stan_data_files(sa.datafiles)
                    #A temporary hack
                    if 'Ndata' in sa.data:
                        sa.iter = sa.data['Ndata']/sa.chains+sa.warmup
                input_param, result = stan_cache(**(sa.gen_arg_dict()))
                try:
                    from morpho.postprocessing import stan_utility as util
                except ImportError:
                    pass
                checks = util.check_all_diagnostics(result)
                logger.info('Result of the sampling: \n{}'.format(result))
                logger.info('Diagnostic info: \n' + checks)
            except Exception as err:
                logger.critical("Caught exception")
                raise
                sys.exit(2)
            try:
                logger.info("Saving results")
                stanres = write_result(sa, result, input_param)
                if sa.out_fit != None:
                    save_object(stanres, sa.out_fit)
                    logger.debug('Saved fit in {}'.format(sa.out_fit))
            except Exception as err:
                logger.critical("Caught exception")
                raise
                sys.exit(2)

        if (sa.get_do_pp()):
            postprocessing(sa)

        if (sa.get_do_plots()):
            list_canvas = plotting(sa)

        if(sa.get_wait()):
            raw_input('Press <ret> to end -> ')

    logger.info("This is all for now!")
